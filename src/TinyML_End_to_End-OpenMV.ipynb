{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports and Version Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Input\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input\n",
    "from tensorflow.keras.applications import MobileNet\n",
    "from tensorflow.keras.preprocessing.image import (ImageDataGenerator, Iterator,\n",
    "                                       array_to_img, img_to_array, load_img)\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard, EarlyStopping\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras import layers\n",
    "import sys, os\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "import tensorflow_model_optimization as tfmot\n",
    "import shap\n",
    "import keras\n",
    "import matplotlib.cm as cm\n",
    "from IPython.display import Image\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "# os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"   # see issue #152\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "# config = tf.compat.v1.ConfigProto()\n",
    "# config.gpu_options.allow_growth = True\n",
    "# sess = tf.compat.v1.Session(config=config)\n",
    "# sess.as_default()\n",
    "\n",
    "# physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "# for physical_device in physical_devices:\n",
    "#     tf.config.experimental.set_memory_growth(physical_device, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.gpu_device_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.3.0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_dir = '../../TinyCollision/data/CollisionData/'\n",
    "\n",
    "img_width, img_height = 96, 96 # 224, 224\n",
    "nb_train_samples = 730 \n",
    "nb_validation_samples = 181\n",
    "epochs = 25\n",
    "batch_size = 16\n",
    "\n",
    "if K.image_data_format() == 'channels_first': \n",
    "    input_shape = (3, img_width, img_height) \n",
    "else: \n",
    "    input_shape = (img_width, img_height, 3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 911 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1./255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    ) # set validation split\n",
    "\n",
    "#### train with 100% of data. See other notebooks for validation of the models\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary') # set as training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Architectures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [] # can be used for multiple models, for this we are using a single model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tiny Compatible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "finetune_model_CNN = tf.keras.Sequential([\n",
    "    layers.InputLayer(input_shape=input_shape),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Conv2D(filters=16, kernel_size=5, padding='same', activation='relu'),\n",
    "    layers.MaxPool2D(),\n",
    "    \n",
    "    layers.BatchNormalization(),\n",
    "    layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
    "    layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
    "    layers.MaxPool2D(),\n",
    "    \n",
    "    layers.BatchNormalization(),\n",
    "    layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
    "    layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
    "    layers.MaxPool2D(),\n",
    "    \n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "finetune_model_CNN._name=\"Custom_CNN\"\n",
    "\n",
    "finetune_model_CNN.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(lr = 1e-5, decay = 1e-5),\n",
    "    loss='binary_crossentropy', \n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "models.append(finetune_model_CNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Custom_CNN\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "batch_normalization (BatchNo (None, 96, 96, 3)         12        \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 96, 96, 16)        1216      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 48, 48, 16)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 48, 48, 16)        64        \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 48, 48, 32)        4640      \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 48, 48, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 24, 24, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 24, 24, 64)        18496     \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 24, 24, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 9216)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               1179776   \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 1,258,829\n",
      "Trainable params: 1,258,727\n",
      "Non-trainable params: 102\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "finetune_model_CNN.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "Training and Testing Model: Custom_CNN\n",
      "Epoch 1/25\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.5966 - accuracy: 0.7028WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "45/45 [==============================] - 9s 203ms/step - loss: 0.5966 - accuracy: 0.7028\n",
      "Epoch 2/25\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.5520 - accuracy: 0.7371WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "45/45 [==============================] - 9s 200ms/step - loss: 0.5520 - accuracy: 0.7371\n",
      "Epoch 3/25\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.4936 - accuracy: 0.7677WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "45/45 [==============================] - 9s 200ms/step - loss: 0.4936 - accuracy: 0.7677\n",
      "Epoch 4/25\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.4455 - accuracy: 0.7806WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "45/45 [==============================] - 9s 201ms/step - loss: 0.4455 - accuracy: 0.7806\n",
      "Epoch 5/25\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.4429 - accuracy: 0.7914WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "45/45 [==============================] - 9s 199ms/step - loss: 0.4429 - accuracy: 0.7914\n",
      "Epoch 6/25\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.4151 - accuracy: 0.8011WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "45/45 [==============================] - 9s 199ms/step - loss: 0.4151 - accuracy: 0.8011\n",
      "Epoch 7/25\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.4069 - accuracy: 0.8067WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "45/45 [==============================] - 9s 201ms/step - loss: 0.4069 - accuracy: 0.8067\n",
      "Epoch 8/25\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.3659 - accuracy: 0.8317WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "45/45 [==============================] - 9s 200ms/step - loss: 0.3659 - accuracy: 0.8317\n",
      "Epoch 9/25\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.3648 - accuracy: 0.8275WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "45/45 [==============================] - 9s 201ms/step - loss: 0.3648 - accuracy: 0.8275\n",
      "Epoch 10/25\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.3221 - accuracy: 0.8595WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "45/45 [==============================] - 9s 201ms/step - loss: 0.3221 - accuracy: 0.8595\n",
      "Epoch 11/25\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.3283 - accuracy: 0.8389WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "45/45 [==============================] - 9s 201ms/step - loss: 0.3283 - accuracy: 0.8389\n",
      "Epoch 12/25\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.3128 - accuracy: 0.8625WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "45/45 [==============================] - 9s 200ms/step - loss: 0.3128 - accuracy: 0.8625\n",
      "Epoch 13/25\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.3012 - accuracy: 0.8609WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "45/45 [==============================] - 9s 200ms/step - loss: 0.3012 - accuracy: 0.8609\n",
      "Epoch 14/25\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.3134 - accuracy: 0.8707WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "45/45 [==============================] - 9s 200ms/step - loss: 0.3134 - accuracy: 0.8707\n",
      "Epoch 15/25\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.2929 - accuracy: 0.8637WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "45/45 [==============================] - 9s 201ms/step - loss: 0.2929 - accuracy: 0.8637\n",
      "Epoch 16/25\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.2883 - accuracy: 0.8750WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "45/45 [==============================] - 9s 200ms/step - loss: 0.2883 - accuracy: 0.8750\n",
      "Epoch 17/25\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.2894 - accuracy: 0.8681WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "45/45 [==============================] - 9s 201ms/step - loss: 0.2894 - accuracy: 0.8681\n",
      "Epoch 18/25\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.2969 - accuracy: 0.8637WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "45/45 [==============================] - 9s 200ms/step - loss: 0.2969 - accuracy: 0.8637\n",
      "Epoch 19/25\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.2688 - accuracy: 0.8887WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "45/45 [==============================] - 9s 199ms/step - loss: 0.2688 - accuracy: 0.8887\n",
      "Epoch 20/25\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.2682 - accuracy: 0.8943WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "45/45 [==============================] - 9s 200ms/step - loss: 0.2682 - accuracy: 0.8943\n",
      "Epoch 21/25\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.2670 - accuracy: 0.8901WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "45/45 [==============================] - 9s 200ms/step - loss: 0.2670 - accuracy: 0.8901\n",
      "Epoch 22/25\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.2698 - accuracy: 0.8748WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "45/45 [==============================] - 9s 200ms/step - loss: 0.2698 - accuracy: 0.8748\n",
      "Epoch 23/25\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.2771 - accuracy: 0.8873WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "45/45 [==============================] - 9s 199ms/step - loss: 0.2771 - accuracy: 0.8873\n",
      "Epoch 24/25\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.2660 - accuracy: 0.8929WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "45/45 [==============================] - 9s 200ms/step - loss: 0.2660 - accuracy: 0.8929\n",
      "Epoch 25/25\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.2437 - accuracy: 0.8903WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "45/45 [==============================] - 9s 199ms/step - loss: 0.2437 - accuracy: 0.8903\n",
      "========================================\n"
     ]
    }
   ],
   "source": [
    "callbacks = [\n",
    "             tf.keras.callbacks.EarlyStopping(\n",
    "                 monitor='val_loss', patience = 15,\n",
    "                 min_delta=0.001, restore_best_weights=True\n",
    "             )\n",
    "]\n",
    "\n",
    "history = []\n",
    "\n",
    "for each in models:\n",
    "    print(\"=\"*40)\n",
    "    print(\"Training and Testing Model: %s\" % str(each.name))\n",
    "    temp_history = each.fit(train_generator, \n",
    "        steps_per_epoch = nb_train_samples // batch_size, \n",
    "        epochs = epochs, \n",
    "        validation_steps = nb_validation_samples // batch_size, shuffle=True, callbacks = callbacks) \n",
    "    print(\"=\"*40)\n",
    "    history.append(temp_history)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters:  Custom_CNN\n",
      "1258829\n"
     ]
    }
   ],
   "source": [
    "for each in models:\n",
    "    print(\"Number of parameters:  %s\" % str(each.name))\n",
    "    print(each.count_params())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of Ops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of OPS:  Custom_CNN\n",
      "WARNING:tensorflow:From /home/sdmohant/.virtualenvs/python3deep/lib/python3.5/site-packages/tensorflow/python/profiler/internal/flops_registry.py:142: tensor_shape_from_node_def_name (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.tensor_shape_from_node_def_name`\n",
      "2516668\n"
     ]
    }
   ],
   "source": [
    "def get_flops(model_h5_path):\n",
    "    session = tf.compat.v1.Session()\n",
    "    graph = tf.compat.v1.get_default_graph()\n",
    "\n",
    "    with graph.as_default():\n",
    "        with session.as_default():\n",
    "            model = tf.keras.models.load_model(model_h5_path)\n",
    "            run_meta = tf.compat.v1.RunMetadata()\n",
    "            opts = tf.compat.v1.profiler.ProfileOptionBuilder.float_operation()\n",
    "            flops = tf.compat.v1.profiler.profile(graph=graph,\n",
    "                                                  run_meta=run_meta, cmd='op', options=opts)\n",
    "\n",
    "    tf.compat.v1.reset_default_graph()\n",
    "\n",
    "    return flops.total_float_ops\n",
    "\n",
    "for each in models:\n",
    "    model_file = '../my-log-dir/saved_model/' + str(each.name) + '.h5'\n",
    "    print(\"Number of OPS:  %s\" % str(each.name))\n",
    "    print(get_flops(model_file))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:  Custom_CNN\n",
      "Size(mb): 15\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "for each in models:\n",
    "    model_file = '../my-log-dir//saved_model/' + str(each.name) + '.h5'\n",
    "    print(\"Model:  %s\" % str(each.name))\n",
    "    b = os.path.getsize(model_file)\n",
    "    print (\"Size(mb): %d\" % (b/1000000))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_file = '../my-log-dir/saved_model/Custom_CNN.h5'\n",
    "model = tf.keras.models.load_model(model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/sdmohant/.virtualenvs/python3deep/lib/python3.5/site-packages/tensorflow_model_optimization/python/core/sparsity/keras/pruning_wrapper.py:219: Layer.add_variable (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.add_weight` method instead.\n",
      "Model: \"Custom_CNN\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "prune_low_magnitude_batch_no (None, 96, 96, 3)         13        \n",
      "_________________________________________________________________\n",
      "prune_low_magnitude_conv2d ( (None, 96, 96, 16)        2418      \n",
      "_________________________________________________________________\n",
      "prune_low_magnitude_max_pool (None, 48, 48, 16)        1         \n",
      "_________________________________________________________________\n",
      "prune_low_magnitude_batch_no (None, 48, 48, 16)        65        \n",
      "_________________________________________________________________\n",
      "prune_low_magnitude_conv2d_1 (None, 48, 48, 32)        9250      \n",
      "_________________________________________________________________\n",
      "prune_low_magnitude_conv2d_2 (None, 48, 48, 32)        18466     \n",
      "_________________________________________________________________\n",
      "prune_low_magnitude_max_pool (None, 24, 24, 32)        1         \n",
      "_________________________________________________________________\n",
      "prune_low_magnitude_batch_no (None, 24, 24, 32)        129       \n",
      "_________________________________________________________________\n",
      "prune_low_magnitude_conv2d_3 (None, 24, 24, 64)        36930     \n",
      "_________________________________________________________________\n",
      "prune_low_magnitude_conv2d_4 (None, 24, 24, 64)        73794     \n",
      "_________________________________________________________________\n",
      "prune_low_magnitude_max_pool (None, 12, 12, 64)        1         \n",
      "_________________________________________________________________\n",
      "prune_low_magnitude_flatten  (None, 9216)              1         \n",
      "_________________________________________________________________\n",
      "prune_low_magnitude_dense (P (None, 128)               2359426   \n",
      "_________________________________________________________________\n",
      "prune_low_magnitude_dropout  (None, 128)               1         \n",
      "_________________________________________________________________\n",
      "prune_low_magnitude_dense_1  (None, 64)                16450     \n",
      "_________________________________________________________________\n",
      "prune_low_magnitude_dropout_ (None, 64)                1         \n",
      "_________________________________________________________________\n",
      "prune_low_magnitude_dense_2  (None, 1)                 131       \n",
      "=================================================================\n",
      "Total params: 2,517,078\n",
      "Trainable params: 1,258,727\n",
      "Non-trainable params: 1,258,351\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "end_step = np.ceil(1.0 * nb_train_samples / batch_size).astype(np.int32) * epochs\n",
    "\n",
    "pruning_schedule = tfmot.sparsity.keras.PolynomialDecay(initial_sparsity=0.50,\n",
    "                                                   final_sparsity=0.90,\n",
    "                                                   begin_step=0,\n",
    "                                                   end_step=end_step,\n",
    "                                                   frequency=100)\n",
    "\n",
    "model_for_pruning = tfmot.sparsity.keras.prune_low_magnitude(model, pruning_schedule=pruning_schedule)\n",
    "model_for_pruning.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      " 1/45 [..............................] - ETA: 0s - loss: 0.2683 - accuracy: 0.8750WARNING:tensorflow:From /home/sdmohant/.virtualenvs/python3deep/lib/python3.5/site-packages/tensorflow/python/ops/summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
      "Instructions for updating:\n",
      "use `tf.profiler.experimental.stop` instead.\n",
      "45/45 [==============================] - 9s 205ms/step - loss: 0.4282 - accuracy: 0.7903\n",
      "Epoch 2/25\n",
      "45/45 [==============================] - 9s 204ms/step - loss: 0.3134 - accuracy: 0.8581\n",
      "Epoch 3/25\n",
      "45/45 [==============================] - 9s 200ms/step - loss: 0.3196 - accuracy: 0.8484\n",
      "Epoch 4/25\n",
      "45/45 [==============================] - 9s 200ms/step - loss: 0.2605 - accuracy: 0.8846\n",
      "Epoch 5/25\n",
      "45/45 [==============================] - 9s 201ms/step - loss: 0.2660 - accuracy: 0.8736\n",
      "Epoch 6/25\n",
      "45/45 [==============================] - 9s 202ms/step - loss: 0.2314 - accuracy: 0.8943\n",
      "Epoch 7/25\n",
      "45/45 [==============================] - 9s 201ms/step - loss: 0.2057 - accuracy: 0.8972\n",
      "Epoch 8/25\n",
      "45/45 [==============================] - 9s 201ms/step - loss: 0.2220 - accuracy: 0.9054\n",
      "Epoch 9/25\n",
      "45/45 [==============================] - 9s 200ms/step - loss: 0.1858 - accuracy: 0.9263\n",
      "Epoch 10/25\n",
      "45/45 [==============================] - 9s 201ms/step - loss: 0.2232 - accuracy: 0.9124\n",
      "Epoch 11/25\n",
      "45/45 [==============================] - 9s 201ms/step - loss: 0.1996 - accuracy: 0.9152\n",
      "Epoch 12/25\n",
      "45/45 [==============================] - 9s 200ms/step - loss: 0.2370 - accuracy: 0.8929\n",
      "Epoch 13/25\n",
      "45/45 [==============================] - 9s 201ms/step - loss: 0.1996 - accuracy: 0.9181\n",
      "Epoch 14/25\n",
      "45/45 [==============================] - 9s 204ms/step - loss: 0.2293 - accuracy: 0.8889\n",
      "Epoch 15/25\n",
      "45/45 [==============================] - 9s 201ms/step - loss: 0.1977 - accuracy: 0.9263\n",
      "Epoch 16/25\n",
      "45/45 [==============================] - 9s 202ms/step - loss: 0.2223 - accuracy: 0.9096\n",
      "Epoch 17/25\n",
      "45/45 [==============================] - 9s 202ms/step - loss: 0.1993 - accuracy: 0.9096\n",
      "Epoch 18/25\n",
      "45/45 [==============================] - 9s 201ms/step - loss: 0.2367 - accuracy: 0.8943\n",
      "Epoch 19/25\n",
      "45/45 [==============================] - 9s 201ms/step - loss: 0.2213 - accuracy: 0.8846\n",
      "Epoch 20/25\n",
      "45/45 [==============================] - 9s 200ms/step - loss: 0.2335 - accuracy: 0.8762\n",
      "Epoch 21/25\n",
      "45/45 [==============================] - 9s 202ms/step - loss: 0.2326 - accuracy: 0.8734\n",
      "Epoch 22/25\n",
      "45/45 [==============================] - 9s 201ms/step - loss: 0.2330 - accuracy: 0.8583\n",
      "Epoch 23/25\n",
      "45/45 [==============================] - 9s 203ms/step - loss: 0.2126 - accuracy: 0.8901\n",
      "Epoch 24/25\n",
      "45/45 [==============================] - 9s 202ms/step - loss: 0.2240 - accuracy: 0.8776\n",
      "Epoch 25/25\n",
      "45/45 [==============================] - 9s 203ms/step - loss: 0.2203 - accuracy: 0.8804\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7ff3f42f2048>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logdir = '../my-log-dir/'\n",
    "\n",
    "callbacks = [\n",
    "  tfmot.sparsity.keras.UpdatePruningStep(),\n",
    "  tfmot.sparsity.keras.PruningSummaries(log_dir=logdir),\n",
    "]\n",
    "\n",
    "model_for_pruning.compile(\n",
    "    optimizer='adam',\n",
    "    loss='binary_crossentropy', \n",
    "    metrics=['accuracy']\n",
    ")\n",
    "  \n",
    "model_for_pruning.fit(train_generator, \n",
    "    steps_per_epoch = nb_train_samples // batch_size, \n",
    "    epochs = epochs,\n",
    "    validation_steps = nb_validation_samples // batch_size, shuffle=True, callbacks = callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Export Pruned Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Custom_CNN\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "batch_normalization (BatchNo (None, 96, 96, 3)         12        \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 96, 96, 16)        1216      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 48, 48, 16)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 48, 48, 16)        64        \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 48, 48, 32)        4640      \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 48, 48, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 24, 24, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 24, 24, 64)        18496     \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 24, 24, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 9216)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               1179776   \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 1,258,829\n",
      "Trainable params: 1,258,727\n",
      "Non-trainable params: 102\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow_model_optimization.sparsity import keras as sparsity\n",
    "\n",
    "final_model = sparsity.strip_pruning(model_for_pruning)\n",
    "final_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_normalization/gamma:0 -- Total:3, Zeros: 0.00%\n",
      "batch_normalization/beta:0 -- Total:3, Zeros: 0.00%\n",
      "batch_normalization/moving_mean:0 -- Total:3, Zeros: 0.00%\n",
      "batch_normalization/moving_variance:0 -- Total:3, Zeros: 0.00%\n",
      "conv2d/kernel:0 -- Total:1200, Zeros: 90.00%\n",
      "conv2d/bias:0 -- Total:16, Zeros: 0.00%\n",
      "batch_normalization_1/gamma:0 -- Total:16, Zeros: 0.00%\n",
      "batch_normalization_1/beta:0 -- Total:16, Zeros: 0.00%\n",
      "batch_normalization_1/moving_mean:0 -- Total:16, Zeros: 0.00%\n",
      "batch_normalization_1/moving_variance:0 -- Total:16, Zeros: 0.00%\n",
      "conv2d_1/kernel:0 -- Total:4608, Zeros: 90.00%\n",
      "conv2d_1/bias:0 -- Total:32, Zeros: 0.00%\n",
      "conv2d_2/kernel:0 -- Total:9216, Zeros: 90.00%\n",
      "conv2d_2/bias:0 -- Total:32, Zeros: 0.00%\n",
      "batch_normalization_2/gamma:0 -- Total:32, Zeros: 0.00%\n",
      "batch_normalization_2/beta:0 -- Total:32, Zeros: 0.00%\n",
      "batch_normalization_2/moving_mean:0 -- Total:32, Zeros: 0.00%\n",
      "batch_normalization_2/moving_variance:0 -- Total:32, Zeros: 0.00%\n",
      "conv2d_3/kernel:0 -- Total:18432, Zeros: 90.00%\n",
      "conv2d_3/bias:0 -- Total:64, Zeros: 0.00%\n",
      "conv2d_4/kernel:0 -- Total:36864, Zeros: 90.00%\n",
      "conv2d_4/bias:0 -- Total:64, Zeros: 0.00%\n",
      "dense/kernel:0 -- Total:1179648, Zeros: 90.00%\n",
      "dense/bias:0 -- Total:128, Zeros: 0.00%\n",
      "dense_1/kernel:0 -- Total:8192, Zeros: 90.00%\n",
      "dense_1/bias:0 -- Total:64, Zeros: 0.00%\n",
      "dense_2/kernel:0 -- Total:64, Zeros: 90.62%\n",
      "dense_2/bias:0 -- Total:1, Zeros: 0.00%\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "import numpy as np\n",
    "\n",
    "# model = tf.keras.models.load_model(final_model)\n",
    "\n",
    "\n",
    "for i, w in enumerate(final_model.get_weights()):\n",
    "    print(\n",
    "        \"{} -- Total:{}, Zeros: {:.2f}%\".format(\n",
    "            final_model.weights[i].name, w.size, np.sum(w == 0) / w.size * 100\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Pruned Model Size and Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving pruned model to:  ../my-log-dir/saved_model/pruned_model.pb\n",
      "WARNING:tensorflow:From /home/sdmohant/.virtualenvs/python3deep/lib/python3.5/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "WARNING:tensorflow:From /home/sdmohant/.virtualenvs/python3deep/lib/python3.5/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "INFO:tensorflow:Assets written to: ../my-log-dir/saved_model/pruned_model.pb/assets\n",
      "Size of the pruned model: 0.00 Mb\n"
     ]
    }
   ],
   "source": [
    "import tempfile\n",
    "import zipfile\n",
    "\n",
    "# _, new_pruned_keras_file = tempfile.mkstemp(\".h5\")\n",
    "\n",
    "new_pruned_keras_file = \"../my-log-dir/saved_model/pruned_model.pb\"\n",
    "print(\"Saving pruned model to: \", new_pruned_keras_file)\n",
    "tf.keras.models.save_model(final_model, new_pruned_keras_file, include_optimizer=False)\n",
    "print(\n",
    "    \"Size of the pruned model: %.2f Mb\"\n",
    "    % (os.path.getsize(new_pruned_keras_file) / float(2 ** 20))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Post training quantization\n",
    "##### Full integer quantization. \n",
    "\n",
    "To 8-bits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp5i29j6i7/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp5i29j6i7/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(911, 96, 96, 3)\n"
     ]
    }
   ],
   "source": [
    "keras_model = tf.keras.models.load_model(new_pruned_keras_file)\n",
    "\n",
    "tflite_fullint_model_file = \"../my-log-dir/saved_model/post_fullint_quantized.tflite\"\n",
    "\n",
    "# converter = tf.lite.TFLiteConverter.from_saved_model('../log/saved_model/pruned_model.pb')\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(final_model)\n",
    "\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "\n",
    "\n",
    "\n",
    "num_calibration_steps = 1\n",
    "def representative_dataset_gen():\n",
    "    for _ in range(num_calibration_steps):\n",
    "        # Get sample input data as a numpy array in a method of your choosing.\n",
    "        ## Ideally we should do a validation calibration but we are using all of the training data for max acc\n",
    "#         x =np.concatenate([validation_generator.next()[0] for i in range(validation_generator.__len__())])\n",
    "        x =np.concatenate([train_generator.next()[0] for i in range(train_generator.__len__())])\n",
    "        print(x.shape)\n",
    "        yield [x]\n",
    "converter.representative_dataset = representative_dataset_gen\n",
    "\n",
    "\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "converter.inference_input_type = tf.int8  # or tf.uint8\n",
    "converter.inference_output_type = tf.int8  # or tf.uint8\n",
    "\n",
    "tflite_model = converter.convert()\n",
    "with open(tflite_fullint_model_file, \"wb\") as f:\n",
    "    f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output Files\n",
    "\n",
    "`pruned_model.pb` - Pruned model file (file size is not going to reduce but the sparsity is incorporated)\n",
    "\n",
    "`post_fullint_quantized.tflite` - Integer 8-bit quantized model \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantized Model to OpenMV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3deep",
   "language": "python",
   "name": "python3deep"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
